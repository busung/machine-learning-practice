{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12. RNN(소웨융 14주차).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKSNpb/GLwuAUJb7SyBSx8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busung/machine-learning-practice/blob/main/12_RNN(%EC%86%8C%EC%9B%A8%EC%9C%B5_14%EC%A3%BC%EC%B0%A8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "xCF50u5vSNCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDB"
      ],
      "metadata": {
        "id": "lwVhqOKySRBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ttuXKJG-RuNI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)#자주 나오는 단어 500개를 뽑아줌(빈도로 만든 어휘사전)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input.shape,test_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcNaL9capHlJ",
        "outputId": "bc9939e0-01bc-41a2-c952-0af5d4c2f5e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_input[0]))\n",
        "print(len(train_input[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yLnJ0ZupP6j",
        "outputId": "546a2909-8dae-4506-8b1d-a1af6b62d946"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 = 문장의 시작, 2 = num_wrods의 500개에 포함되지 않는다.\n",
        "print(train_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Lzbn9PpU0p",
        "outputId": "131ac15c-003c-4026-8c65-d87745ded4af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_target[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfnVqfyOpXmj",
        "outputId": "de325195-e4f5-42fa-9050-3dad9847ef46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "lengths = np.array([len(x) for x in train_input])"
      ],
      "metadata": {
        "id": "LN6MQRY4tDMt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(lengths),np.median(lengths))#중간값과 평균의 차이가 크다 = 데이터가 편향되어 있다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DObNXImAs-s7",
        "outputId": "2e7725ea-4bb5-4d7a-b718-d24badc2a6bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238.71364 178.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#대표성을 가지는 문장 길이를 정하기 위해 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(lengths,bins=15)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dvEQ9KI-tbXE",
        "outputId": "b3a89693-71f3-4021-f95d-400a88de1105"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스 패딩\n",
        "* 대표성을 가지는 길이를 100이라고 선택\n",
        "* 문장의 길이를 모두 100으로 맞추는 전처리 과정\n",
        "* 길면 자르고 짧으면 0으로 100을 맞춤\n",
        "  * 이 때 기본적으로 뒤를 자르지만, 언어에 따라 중요한 부분이 다르기에 사용자가 지정해 줘야함\n",
        "* 문장 시작 숫자가 1이기에 0이면 아무 지장이 없음"
      ],
      "metadata": {
        "id": "cA2iHVdFu5-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "train_seq = pad_sequences(train_input, maxlen=100) \n",
        "val_seq = pad_sequences(test_input, maxlen=100) "
      ],
      "metadata": {
        "id": "c5LGmj-IuJ1v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHIKJ2N6t3G6",
        "outputId": "b0c2954d-74f8-4eae-e238-d3cb6419787f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링"
      ],
      "metadata": {
        "id": "Xn4leGMY0jsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.SimpleRNN(8, input_shape = (100,500)))#train,test set을 one-hot encoding 해 줌, 이 때 총 단어수가 500개이므로 한 단어는 크기 500의 vector가 됨\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xqFH7JEL0lBI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_oh = keras.utils.to_categorical(train_seq)\n",
        "train_oh[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSITRq205sT",
        "outputId": "04c63647-b2f9-4fca-e4f8-475eadea4f46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaxjf5SO2ISV",
        "outputId": "2c6a74ad-1626-4693-f9a6-56488752d92d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(train_oh[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWpurwMu2pXu",
        "outputId": "33377ba0-b99e-446c-86bf-efc007d1cfde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_oh = keras.utils.to_categorical(val_seq)"
      ],
      "metadata": {
        "id": "TZQmB_Ds216A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbnt2FXE3C-D",
        "outputId": "a1cfc397-7f69-4eab-de03-6799a93d36aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 8)                 4072      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,081\n",
            "Trainable params: 4,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련"
      ],
      "metadata": {
        "id": "1yqOJgpB3K5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "model.compile(optimizer = rmsprop, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights = True)\n",
        "history = model.fit(train_oh,train_target,epochs = 100, batch_size=64, validation_data = (val_oh,test_target))"
      ],
      "metadata": {
        "id": "jo5fpB5A3Mmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ErsMVIM4wui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 임베딩\n",
        "* 원-핫 인코딩은 너무 비효율적\n",
        "* 단어를 vector화 함으로써 조금 더 효율적인 연산가능"
      ],
      "metadata": {
        "id": "CPR3OBMl5Img"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.Embedding(500,16,input_length=100))#500의 단어들을 크기 16의 vector로 임베딩 해달라, 이 때 input은 100이 들어옴\n",
        "model2.add(keras.layers.SimpleRNN(8))\n",
        "model2.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "vOSprGYU5Q3B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()\n",
        "#8*16(완전연결)+8*8(RNN끼리의 순환연결)+8(절편)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30nRBTrm6FGE",
        "outputId": "49db755b-b6dc-4d01-90d5-f6e2f0fddc05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 8)                 200       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,209\n",
            "Trainable params: 8,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "model2.compile(optimizer = rmsprop, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights = True)\n",
        "history = model2.fit(train_oh,train_target,epochs = 100, batch_size=64, validation_data = (val_oh,test_target))"
      ],
      "metadata": {
        "id": "PF1zbkQ26Kl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2yp3GDOC6wuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "U5YCK3P56ywT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Embedding(500,16,input_length=100))#500의 단어들을 크기 16의 vector로 임베딩 해달라, 이 때 input은 100이 들어옴\n",
        "model3.add(keras.layers.LSTM(8))\n",
        "model3.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "-8HUNTRT608F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()\n",
        "#SimpleRNN의 4배 많은 800개(한 셀당 4개의 가중치가 더 있으므로)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji5Ne2iS9gPM",
        "outputId": "5c218a6a-1d76-4ba1-ac39-22646d698291"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 8)                 800       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,809\n",
            "Trainable params: 8,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate = 1e-4)\n",
        "model3.compile(optimizer = rmsprop, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights = True)\n",
        "history = model3.fit(train_oh,train_target,epochs = 100, batch_size=64, validation_data = (val_oh,test_target))"
      ],
      "metadata": {
        "id": "eFgyQhGl_GdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l88YfbPu_L6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout 적용"
      ],
      "metadata": {
        "id": "RyHs_LnX_OwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = keras.Sequential()\n",
        "\n",
        "model4.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model4.add(keras.layers.LSTM(8, dropout=0.3))\n",
        "model4.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "UQDtB-Pp_QhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model4.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-dropout-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
        "history = model4.fit(train_seq, train_target, epochs=100, batch_size=64,validation_data=(val_seq, val_target),callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "hCGJwlv7_k81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JTRZveE9_mlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다층 연결"
      ],
      "metadata": {
        "id": "HXFGJF4j_t3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = keras.Sequential()\n",
        "\n",
        "model5.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model5.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True))#LSTM의 다층연결에선 모든 Timestep이 반환되어야 하기 때문\n",
        "model5.add(keras.layers.LSTM(8, dropout=0.3))\n",
        "model5.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucvxlucS_wgV",
        "outputId": "52809c0a-2021-492a-9647-9acd48d5707a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 8)            800       \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 8)                 544       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,353\n",
            "Trainable params: 9,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model5.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-2rnn-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
        "history = model5.fit(train_seq, train_target, epochs=100, batch_size=64,validation_data=(val_seq, val_target),callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "54K7tWSFAZAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "utDDfVlZAagM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU\n",
        "* 파라미터수를 줄여 성능은 비슷하지만 속도는 빠른 모델"
      ],
      "metadata": {
        "id": "TmetxGMkAv3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = keras.Sequential()\n",
        "\n",
        "model6.add(keras.layers.Embedding(500, 16, input_length=100))\n",
        "model6.add(keras.layers.GRU(8))\n",
        "model6.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yd0by6JA0MF",
        "outputId": "33ffb919-45d1-4397-caf2-ab162c07b3b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 8)                 624       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,633\n",
            "Trainable params: 8,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model6.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-gru-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
        "history = model6.fit(train_seq, train_target, epochs=100, batch_size=64,validation_data=(val_seq, val_target),callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "vXmps6_MBACB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N0_oJiWGBDz-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
